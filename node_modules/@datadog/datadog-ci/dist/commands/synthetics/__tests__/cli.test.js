"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const advanced_1 = require("clipanion/lib/advanced");
const deep_extend_1 = __importDefault(require("deep-extend"));
const ciUtils = __importStar(require("../../../helpers/utils"));
const command_1 = require("../command");
const interfaces_1 = require("../interfaces");
const runTests = __importStar(require("../run-test"));
const utils = __importStar(require("../utils"));
const fixtures_1 = require("./fixtures");
test('all option flags are supported', () => __awaiter(void 0, void 0, void 0, function* () {
    const options = [
        'apiKey',
        'appKey',
        'failOnCriticalErrors',
        'config',
        'datadogSite',
        'files',
        'failOnTimeout',
        'public-id',
        'search',
        'subdomain',
        'tunnel',
        'jUnitReport',
        'runName',
    ];
    const cli = new advanced_1.Cli();
    cli.register(command_1.RunTestCommand);
    const usage = cli.usage(command_1.RunTestCommand);
    options.forEach((option) => expect(usage).toContain(`--${option}`));
}));
const getAxiosHttpError = (status, error) => {
    const serverError = new Error(error);
    serverError.response = { data: { errors: [error] }, status };
    serverError.config = { baseURL: 'baseURL', url: 'url' };
    return serverError;
};
describe('run-test', () => {
    beforeEach(() => {
        jest.restoreAllMocks();
        jest.spyOn(ciUtils, 'getConfig').mockImplementation(() => __awaiter(void 0, void 0, void 0, function* () { return ({}); }));
        process.env = {};
    });
    describe('getAppBaseURL', () => {
        beforeEach(() => {
            jest.restoreAllMocks();
        });
        test('should default to datadog us', () => __awaiter(void 0, void 0, void 0, function* () {
            process.env = {};
            const command = new command_1.RunTestCommand();
            expect(command['getAppBaseURL']()).toBe('https://app.datadoghq.com/');
        }));
        test('subdomain should be overridable', () => __awaiter(void 0, void 0, void 0, function* () {
            process.env = { DATADOG_SUBDOMAIN: 'custom' };
            const command = new command_1.RunTestCommand();
            yield command['resolveConfig']();
            expect(command['getAppBaseURL']()).toBe('https://custom.datadoghq.com/');
        }));
        test('should override subdomain and site', () => __awaiter(void 0, void 0, void 0, function* () {
            process.env = {
                DATADOG_SITE: 'datadoghq.eu',
                DATADOG_SUBDOMAIN: 'custom',
            };
            const command = new command_1.RunTestCommand();
            yield command['resolveConfig']();
            expect(command['getAppBaseURL']()).toBe('https://custom.datadoghq.eu/');
        }));
    });
    describe('sortResultsByOutcome', () => {
        beforeEach(() => {
            jest.restoreAllMocks();
        });
        const test1 = fixtures_1.getApiTest('test1');
        const test2 = deep_extend_1.default(fixtures_1.getApiTest('test2'), { options: { ci: { executionRule: interfaces_1.ExecutionRule.BLOCKING } } });
        const test3 = deep_extend_1.default(fixtures_1.getApiTest('test3'), { options: { ci: { executionRule: interfaces_1.ExecutionRule.NON_BLOCKING } } });
        const test4 = deep_extend_1.default(fixtures_1.getApiTest('test4'), { options: { ci: { executionRule: interfaces_1.ExecutionRule.BLOCKING } } });
        const test5 = deep_extend_1.default(fixtures_1.getApiTest('test5'), { options: { ci: { executionRule: interfaces_1.ExecutionRule.NON_BLOCKING } } });
        const resultsWithTest = [
            [test1, deep_extend_1.default(fixtures_1.getApiPollResult('1'), { result: { passed: true } })],
            [test2, deep_extend_1.default(fixtures_1.getApiPollResult('2'), { result: { passed: true } })],
            [test3, deep_extend_1.default(fixtures_1.getApiPollResult('3'), { result: { passed: true } })],
            [test4, deep_extend_1.default(fixtures_1.getApiPollResult('4'), { result: { passed: false } })],
            [test5, deep_extend_1.default(fixtures_1.getApiPollResult('5'), { result: { passed: false } })],
        ];
        test('should sort tests with success, non_blocking failures then failures', () => __awaiter(void 0, void 0, void 0, function* () {
            const command = new command_1.RunTestCommand();
            resultsWithTest.sort(command['sortResultsByOutcome']());
            expect(resultsWithTest).toStrictEqual([
                [test3, deep_extend_1.default(fixtures_1.getApiPollResult('3'), { result: { passed: true } })],
                [test1, deep_extend_1.default(fixtures_1.getApiPollResult('1'), { result: { passed: true } })],
                [test2, deep_extend_1.default(fixtures_1.getApiPollResult('2'), { result: { passed: true } })],
                [test5, deep_extend_1.default(fixtures_1.getApiPollResult('5'), { result: { passed: false } })],
                [test4, deep_extend_1.default(fixtures_1.getApiPollResult('4'), { result: { passed: false } })],
            ]);
        }));
    });
    describe('resolveConfig', () => {
        beforeEach(() => {
            jest.restoreAllMocks();
            process.env = {};
            jest.spyOn(ciUtils, 'getConfig').mockImplementation(() => __awaiter(void 0, void 0, void 0, function* () { return ({}); }));
        });
        test('override from ENV', () => __awaiter(void 0, void 0, void 0, function* () {
            const overrideEnv = {
                DATADOG_API_KEY: 'fake_api_key',
                DATADOG_APP_KEY: 'fake_app_key',
                DATADOG_SITE: 'datadoghq.eu',
                DATADOG_SUBDOMAIN: 'custom',
            };
            process.env = overrideEnv;
            const command = new command_1.RunTestCommand();
            yield command['resolveConfig']();
            expect(command['config']).toEqual(Object.assign(Object.assign({}, command_1.DEFAULT_COMMAND_CONFIG), { apiKey: overrideEnv.DATADOG_API_KEY, appKey: overrideEnv.DATADOG_APP_KEY, datadogSite: overrideEnv.DATADOG_SITE, subdomain: overrideEnv.DATADOG_SUBDOMAIN }));
        }));
        test('override from config file', () => __awaiter(void 0, void 0, void 0, function* () {
            const overrideConfigFile = {
                apiKey: 'fake_api_key',
                appKey: 'fake_app_key',
                configPath: 'fake-datadog-ci.json',
                datadogSite: 'datadoghq.eu',
                failOnCriticalErrors: true,
                failOnTimeout: false,
                files: ['my-new-file'],
                global: { locations: [] },
                locations: [],
                pollingTimeout: 1,
                proxy: { protocol: 'https' },
                publicIds: ['ran-dom-id'],
                subdomain: 'ppa',
                tunnel: true,
                variableStrings: [],
            };
            jest.spyOn(ciUtils, 'getConfig').mockImplementation(() => __awaiter(void 0, void 0, void 0, function* () { return overrideConfigFile; }));
            const command = new command_1.RunTestCommand();
            yield command['resolveConfig']();
            expect(command['config']).toEqual(overrideConfigFile);
        }));
        test('override from CLI', () => __awaiter(void 0, void 0, void 0, function* () {
            const overrideCLI = {
                apiKey: 'fake_api_key',
                appKey: 'fake_app_key',
                configPath: 'fake-datadog-ci.json',
                datadogSite: 'datadoghq.eu',
                failOnCriticalErrors: true,
                failOnTimeout: false,
                files: ['new-file'],
                publicIds: ['ran-dom-id'],
                subdomain: 'new-sub-domain',
                testSearchQuery: 'a-search-query',
                tunnel: true,
            };
            const command = new command_1.RunTestCommand();
            command['apiKey'] = overrideCLI.apiKey;
            command['appKey'] = overrideCLI.appKey;
            command['configPath'] = overrideCLI.configPath;
            command['datadogSite'] = overrideCLI.datadogSite;
            command['failOnCriticalErrors'] = overrideCLI.failOnCriticalErrors;
            command['failOnTimeout'] = overrideCLI.failOnTimeout;
            command['files'] = overrideCLI.files;
            command['publicIds'] = overrideCLI.publicIds;
            command['subdomain'] = overrideCLI.subdomain;
            command['tunnel'] = overrideCLI.tunnel;
            command['testSearchQuery'] = overrideCLI.testSearchQuery;
            yield command['resolveConfig']();
            expect(command['config']).toEqual(Object.assign(Object.assign({}, command_1.DEFAULT_COMMAND_CONFIG), { apiKey: 'fake_api_key', appKey: 'fake_app_key', configPath: 'fake-datadog-ci.json', datadogSite: 'datadoghq.eu', failOnCriticalErrors: true, failOnTimeout: false, files: ['new-file'], publicIds: ['ran-dom-id'], subdomain: 'new-sub-domain', testSearchQuery: 'a-search-query', tunnel: true }));
        }));
        test('override from config file < ENV < CLI', () => __awaiter(void 0, void 0, void 0, function* () {
            jest.spyOn(ciUtils, 'getConfig').mockImplementation(() => __awaiter(void 0, void 0, void 0, function* () {
                return ({
                    apiKey: 'api_key_config_file',
                    appKey: 'app_key_config_file',
                    datadogSite: 'datadog.config.file',
                });
            }));
            process.env = {
                DATADOG_API_KEY: 'api_key_env',
                DATADOG_APP_KEY: 'app_key_env',
            };
            const command = new command_1.RunTestCommand();
            command['apiKey'] = 'api_key_cli';
            yield command['resolveConfig']();
            expect(command['config']).toEqual(Object.assign(Object.assign({}, command_1.DEFAULT_COMMAND_CONFIG), { apiKey: 'api_key_cli', appKey: 'app_key_env', datadogSite: 'datadog.config.file' }));
        }));
        test('override locations with ENV variable', () => __awaiter(void 0, void 0, void 0, function* () {
            const conf = {
                content: { tests: [{ config: {}, id: 'publicId' }] },
                name: 'Suite 1',
            };
            jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, _) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
            jest.spyOn(utils, 'getSuites').mockImplementation((() => [conf]));
            // Throw to stop the test
            const triggerTests = jest.fn(() => {
                throw getAxiosHttpError(502, 'Bad Gateway');
            });
            const apiHelper = {
                getTest: jest.fn(() => (Object.assign({}, fixtures_1.getApiTest('publicId')))),
                triggerTests,
            };
            const write = jest.fn();
            const command = new command_1.RunTestCommand();
            command.context = { stdout: { write } };
            command['config'].global = { locations: ['aws:us-east-2'] };
            jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
            expect(yield command.execute()).toBe(0);
            expect(triggerTests).toHaveBeenCalledWith(expect.objectContaining({
                tests: [{ executionRule: 'blocking', locations: ['aws:us-east-2'], public_id: 'publicId' }],
            }));
            // Env > global
            process.env = {
                DATADOG_SYNTHETICS_LOCATIONS: 'aws:us-east-3',
            };
            expect(yield command.execute()).toBe(0);
            expect(triggerTests).toHaveBeenCalledTimes(2);
            expect(triggerTests).toHaveBeenNthCalledWith(2, expect.objectContaining({
                tests: [{ executionRule: 'blocking', locations: ['aws:us-east-3'], public_id: 'publicId' }],
            }));
            process.env = {
                DATADOG_SYNTHETICS_LOCATIONS: 'aws:us-east-3;aws:us-east-4',
            };
            expect(yield command.execute()).toBe(0);
            expect(triggerTests).toHaveBeenCalledTimes(3);
            expect(triggerTests).toHaveBeenNthCalledWith(3, expect.objectContaining({
                tests: [{ executionRule: 'blocking', locations: ['aws:us-east-3', 'aws:us-east-4'], public_id: 'publicId' }],
            }));
            // Test > env
            const confWithLocation = {
                content: { tests: [{ config: { locations: ['aws:us-east-1'] }, id: 'publicId' }] },
            };
            jest.spyOn(utils, 'getSuites').mockImplementation((() => [confWithLocation]));
            expect(yield command.execute()).toBe(0);
            expect(triggerTests).toHaveBeenCalledWith(expect.objectContaining({
                tests: [{ executionRule: 'blocking', locations: ['aws:us-east-1'], public_id: 'publicId' }],
            }));
        }));
    });
    describe('exit code respects `failOnCriticalErrors`', () => {
        test('404 leading to `NO_TESTS_TO_RUN` never exit with 1', () => __awaiter(void 0, void 0, void 0, function* () {
            const command = new command_1.RunTestCommand();
            command.context = { stdout: { write: jest.fn() } };
            command['config'].failOnCriticalErrors = true;
            const apiHelper = {
                getTest: jest.fn(() => {
                    throw getAxiosHttpError(404, 'Test not found');
                }),
            };
            jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
            jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, _) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
            jest.spyOn(utils, 'getSuites').mockImplementation((() => [fixtures_1.getTestSuite()]));
            expect(yield command.execute()).toBe(0);
            expect(apiHelper.getTest).toHaveBeenCalledTimes(1);
        }));
        test('`NO_RESULTS_TO_POLL` never exit with 1', () => __awaiter(void 0, void 0, void 0, function* () {
            const command = new command_1.RunTestCommand();
            command.context = { stdout: { write: jest.fn() } };
            command['config'].failOnCriticalErrors = true;
            const apiHelper = {
                getTest: () => fixtures_1.getApiTest('123-456-789'),
                triggerTests: jest.fn(() => ({})),
            };
            jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
            jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, _) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
            jest.spyOn(utils, 'getSuites').mockImplementation((() => [fixtures_1.getTestSuite()]));
            expect(yield command.execute()).toBe(0);
            expect(apiHelper.triggerTests).toHaveBeenCalledTimes(1);
        }));
        describe.each([false, true])('%s', (failOnCriticalErrors) => {
            const cases = [['HTTP 4xx error', 403], ['HTTP 5xx error', 502], ['Unknown error']];
            const expectedExit = failOnCriticalErrors ? 1 : 0;
            describe.each(cases)('%s', (_, errorCode) => {
                test('unable to obtain test configurations', () => __awaiter(void 0, void 0, void 0, function* () {
                    const command = new command_1.RunTestCommand();
                    command.context = { stdout: { write: jest.fn() } };
                    command['config'].failOnCriticalErrors = failOnCriticalErrors;
                    command['testSearchQuery'] = 'test:search';
                    const apiHelper = {
                        searchTests: jest.fn(() => {
                            throw errorCode ? getAxiosHttpError(errorCode, 'Error') : new Error('Unknown error');
                        }),
                    };
                    jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
                    jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, __) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
                    expect(yield command.execute()).toBe(expectedExit);
                    expect(apiHelper.searchTests).toHaveBeenCalledTimes(1);
                }));
                test('unavailable test config', () => __awaiter(void 0, void 0, void 0, function* () {
                    const command = new command_1.RunTestCommand();
                    command.context = { stdout: { write: jest.fn() } };
                    command['config'].failOnCriticalErrors = failOnCriticalErrors;
                    const apiHelper = {
                        getTest: jest.fn(() => {
                            throw errorCode ? getAxiosHttpError(errorCode, 'Error') : new Error('Unknown error');
                        }),
                    };
                    jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
                    jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, __) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
                    jest.spyOn(utils, 'getSuites').mockImplementation((() => [fixtures_1.getTestSuite()]));
                    expect(yield command.execute()).toBe(expectedExit);
                    expect(apiHelper.getTest).toHaveBeenCalledTimes(1);
                }));
                test('unable to trigger tests', () => __awaiter(void 0, void 0, void 0, function* () {
                    const command = new command_1.RunTestCommand();
                    command.context = { stdout: { write: jest.fn() } };
                    command['config'].failOnCriticalErrors = failOnCriticalErrors;
                    const apiHelper = {
                        getTest: () => fixtures_1.getApiTest('123-456-789'),
                        triggerTests: jest.fn(() => {
                            throw errorCode ? getAxiosHttpError(errorCode, 'Error') : new Error('Unknown error');
                        }),
                    };
                    jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
                    jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, __) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
                    jest.spyOn(utils, 'getSuites').mockImplementation((() => [fixtures_1.getTestSuite()]));
                    expect(yield command.execute()).toBe(expectedExit);
                    expect(apiHelper.triggerTests).toHaveBeenCalledTimes(1);
                }));
                test('unable to poll test results', () => __awaiter(void 0, void 0, void 0, function* () {
                    const command = new command_1.RunTestCommand();
                    command.context = { stdout: { write: jest.fn() } };
                    command['config'].failOnCriticalErrors = failOnCriticalErrors;
                    const apiHelper = {
                        getTest: () => fixtures_1.getApiTest('123-456-789'),
                        pollResults: jest.fn(() => {
                            throw errorCode ? getAxiosHttpError(errorCode, 'Error') : new Error('Unknown error');
                        }),
                        triggerTests: () => (Object.assign(Object.assign({}, fixtures_1.mockTestTriggerResponse), { results: [{ location: 1, public_id: '123-456-789', result_id: '1' }] })),
                    };
                    jest.spyOn(runTests, 'getApiHelper').mockImplementation(() => apiHelper);
                    jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation((config, __) => __awaiter(void 0, void 0, void 0, function* () { return config; }));
                    jest.spyOn(utils, 'getSuites').mockImplementation((() => [fixtures_1.getTestSuite()]));
                    expect(yield command.execute()).toBe(expectedExit);
                    expect(apiHelper.pollResults).toHaveBeenCalledTimes(1);
                }));
            });
        });
    });
    describe('Render results', () => {
        const emptySummary = utils.createSummary();
        const test1 = {
            configOverride: { executionRule: interfaces_1.ExecutionRule.BLOCKING, startUrl: 'foo' },
            publicId: 'aaa-aaa-aaa',
            resultPassed: true,
        };
        const test1Timeout = Object.assign(Object.assign({}, test1), { resultError: 'Timeout', resultPassed: false });
        const test1CriticalError = Object.assign(Object.assign({}, test1), { resultIsUnhealthy: true, resultPassed: false });
        const test1FailedNonBlocking = Object.assign(Object.assign({}, test1), { configOverride: Object.assign(Object.assign({}, test1.configOverride), { executionRule: interfaces_1.ExecutionRule.NON_BLOCKING, startUrl: 'bar' }), resultPassed: false });
        const test1Failed = Object.assign(Object.assign({}, test1), { configOverride: Object.assign(Object.assign({}, test1.configOverride), { executionRule: interfaces_1.ExecutionRule.BLOCKING, startUrl: 'baz' }), resultPassed: false });
        const test1NonBlocking = Object.assign(Object.assign({}, test1), { executionRule: interfaces_1.ExecutionRule.NON_BLOCKING });
        const test1NonBlockingFailedNonBlocking = Object.assign(Object.assign({}, test1FailedNonBlocking), { executionRule: interfaces_1.ExecutionRule.NON_BLOCKING });
        const test1NonBlockingFailed = Object.assign(Object.assign({}, test1Failed), { executionRule: interfaces_1.ExecutionRule.NON_BLOCKING });
        const test2Failed = {
            configOverride: { executionRule: interfaces_1.ExecutionRule.BLOCKING, startUrl: 'bar' },
            publicId: 'bbb-bbb-bbb',
            resultPassed: false,
        };
        const test3 = {
            configOverride: { executionRule: interfaces_1.ExecutionRule.BLOCKING, startUrl: 'baz' },
            publicId: 'ccc-ccc-ccc',
            resultPassed: true,
        };
        const cases = [
            {
                description: '1 API test with 1 config override, 1 result (passed)',
                expected: {
                    exitCode: 0,
                    summary: Object.assign(Object.assign({}, emptySummary), { passed: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1]),
                summary: Object.assign({}, emptySummary),
            },
            {
                description: '1 API test with 1 config override, 1 result (failed timeout), no fail on timeout, no fail on critical errors',
                expected: {
                    exitCode: 0,
                    summary: Object.assign(Object.assign({}, emptySummary), { passed: 1, timedOut: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1Timeout]),
                summary: Object.assign({}, emptySummary),
            },
            {
                description: '1 API test with 1 config override, 1 result (failed timeout), fail on timeout, no fail on critical errors',
                expected: {
                    exitCode: 1,
                    summary: Object.assign(Object.assign({}, emptySummary), { failed: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: true,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1Timeout]),
                summary: Object.assign({}, emptySummary),
            },
            {
                description: '1 API test with 1 config override, 1 result (failed critical error), no fail on timeout, no fail on critical errors',
                expected: {
                    exitCode: 0,
                    summary: Object.assign(Object.assign({}, emptySummary), { passed: 1, criticalErrors: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1CriticalError]),
                summary: Object.assign({}, emptySummary),
            },
            {
                description: '1 API test with 1 config override, 1 result (failed critical error), no fail on timeout, fail on critical errors',
                expected: {
                    exitCode: 1,
                    summary: Object.assign(Object.assign({}, emptySummary), { failed: 1 }),
                },
                failOnCriticalErrors: true,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1CriticalError]),
                summary: Object.assign({}, emptySummary),
            },
            {
                description: '1 API test (blocking) with 4 config overrides (1 skipped), 3 results (1 passed, 1 failed, 1 failed non-blocking)',
                expected: {
                    exitCode: 1,
                    summary: Object.assign(Object.assign({}, emptySummary), { failed: 1, failedNonBlocking: 1, passed: 1, skipped: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1, test1FailedNonBlocking, test1Failed]),
                summary: Object.assign(Object.assign({}, emptySummary), { skipped: 1 }),
            },
            {
                description: '1 API test (non-blocking) with 4 config overrides (1 skipped), 3 results (1 passed, 1 failed, 1 failed non-blocking)',
                expected: {
                    exitCode: 0,
                    summary: Object.assign(Object.assign({}, emptySummary), { failedNonBlocking: 2, passed: 1, skipped: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([
                    test1NonBlocking,
                    test1NonBlockingFailedNonBlocking,
                    test1NonBlockingFailed,
                ]),
                summary: Object.assign(Object.assign({}, emptySummary), { skipped: 1 }),
            },
            {
                description: '3 API tests (blocking) with 1 config override each, 3 results (1 failed non-blocking, 1 failed, 1 passed)',
                expected: {
                    exitCode: 1,
                    summary: Object.assign(Object.assign({}, emptySummary), { failed: 1, failedNonBlocking: 1, passed: 1 }),
                },
                failOnCriticalErrors: false,
                failOnTimeout: false,
                fixtures: new fixtures_1.RenderResultsHelper().createFixtures([test1FailedNonBlocking, test2Failed, test3]),
                summary: Object.assign({}, emptySummary),
            },
        ];
        test.each(cases)('$description', (testCase) => __awaiter(void 0, void 0, void 0, function* () {
            jest.spyOn(ciUtils, 'parseConfigFile').mockImplementation(() => __awaiter(void 0, void 0, void 0, function* () {
                return (Object.assign(Object.assign({}, command_1.DEFAULT_COMMAND_CONFIG), { failOnCriticalErrors: testCase.failOnCriticalErrors, failOnTimeout: testCase.failOnTimeout }));
            }));
            jest.spyOn(utils, 'getReporter').mockImplementation(() => fixtures_1.mockReporter);
            jest.spyOn(runTests, 'executeTests').mockResolvedValue({
                results: testCase.fixtures.results,
                summary: testCase.summary,
                tests: testCase.fixtures.tests,
                triggers: testCase.fixtures.triggers,
            });
            const command = new command_1.RunTestCommand();
            const write = jest.fn();
            command.context = { stdout: { write } }; // For the DefaultReporter constructor
            const exitCode = yield command.execute();
            const nbResults = Object.values(testCase.fixtures.results).reduce((acc, r) => acc + r.length, 0);
            expect(fixtures_1.mockReporter.testEnd).toHaveBeenCalledTimes(nbResults);
            for (const [testPublicId, results] of Object.entries(testCase.fixtures.results)) {
                for (const result of results) {
                    expect(fixtures_1.mockReporter.testEnd).toHaveBeenCalledWith(testCase.fixtures.tests.find((t) => t.public_id === testPublicId), [result], `https://${command_1.DEFAULT_COMMAND_CONFIG.subdomain}.${command_1.DEFAULT_COMMAND_CONFIG.datadogSite}/`, { [fixtures_1.mockLocation.id.toString()]: fixtures_1.mockLocation.display_name }, testCase.failOnCriticalErrors, testCase.failOnTimeout);
                }
            }
            expect(testCase.summary).toEqual(testCase.expected.summary);
            expect(fixtures_1.mockReporter.runEnd).toHaveBeenCalledWith(testCase.expected.summary);
            expect(exitCode).toBe(testCase.expected.exitCode);
        }));
    });
});
//# sourceMappingURL=cli.test.js.map